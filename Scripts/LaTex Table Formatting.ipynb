{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49a38f94",
   "metadata": {},
   "source": [
    "### File Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf2cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "import os\n",
    "\n",
    "os.chdir(\"../Output_run1/UnformattedLatexTables\")\n",
    "cwd = os.getcwd()\n",
    "\n",
    "newpath = r'../FormattedLatexTables' \n",
    "if not os.path.exists(newpath):\n",
    "    os.makedirs(newpath)\n",
    "\n",
    "#picks out .tex files in working directory\n",
    "allFiles = os.listdir(cwd)\n",
    "\n",
    "texFiles = [f for f in allFiles if f.startswith(\"dfMain2\") and f.endswith(\".tex\")]\n",
    "#print(texFiles) #uncomment to see file list\n",
    "\n",
    "#set covariate list to compile\n",
    "\n",
    "covariates = [\"nNoun\", \"nVerb\", \"nAdj\", \"nAdv\", \"Conc\", \"SemD\", \"SubCD\", \"MemCD\",\n",
    "              \"logWF\", \"nLet\", \"nSyll\", \"pld20\", \"old20\", \"posUni\", \"posBi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee243f3a",
   "metadata": {},
   "source": [
    "### Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dc8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile a .tex file each for Acc and RT\n",
    "#takes in individual .tex files for each simple regression and compile together \n",
    "#adds additional formatting: greys out rows with insignificant effects; \"header\" for each covariate; add 1 colum to left\n",
    "\n",
    "#current output needs to be split into multiple pages manually as needed, or converted into longtable\n",
    "\n",
    "\n",
    "AccSimple = [f for f in texFiles if \"Acc_\" in f and not \"+\" in f] #accuracy files\n",
    "RTSimple = [f for f in texFiles if \"RT_\" in f and not \"+\" in f] #reaction time files\n",
    "\n",
    "def compileSimple(fileList, covList, pg): #takes list of files for dependent variable, list of covariates to include\n",
    "    if pg == 0:\n",
    "        pgNo = \"\"\n",
    "    else:\n",
    "        pgNo = str(pg)\n",
    "    \n",
    "    #get beginning of file names\n",
    "    filePrefix = fileList[0].split('_')[0] \n",
    "    \n",
    "    with open('../FormattedLatexTables/'+filePrefix+'_simpleCollated'+pgNo+'.tex',\"w\") as collatedFile:\n",
    "        collatedFile.write('\\\\begin{table}[H]\\n')\n",
    "        collatedFile.write('\\\\begingroup\\\\normalsize\\n')\n",
    "        collatedFile.write('\\hspace*{-1.5cm}\\n')\n",
    "        collatedFile.write('\\\\begin{tabular}{=p{0cm}lllr+l+r+r+r+r+r+l}\\n')\n",
    "        collatedFile.write('\\hline\\n')\n",
    "        \n",
    "        for cov in covList:\n",
    "            collatedFile.write('\\multicolumn{11}{l}{\\\\textit{Predictor: ' + cov +'}}\\\\\\\\\\n')\n",
    "            \n",
    "            fName = [f for f in fileList if cov in f][0] #assumes that there is only one occurrence in list\n",
    "            with open(fName) as covFile:\n",
    "                writeLine = False\n",
    "                \n",
    "                for line in covFile:\n",
    "                    if line.startswith(\"\\end{tabular}\"): #stop writing lines from covFile\n",
    "                        writeLine = False\n",
    "                        collatedFile.write(\"\\hline\\n\")\n",
    "                        \n",
    "                    if writeLine == True:\n",
    "                        if \"&   \\\\\" in line[-10:-1]:\n",
    "                            collatedFile.write('\\\\rowstyle{\\leavevmode\\color{gray}}\\n') #makes lines with no significance grey\n",
    "                        if not \"\\hline\" in line:\n",
    "                            collatedFile.write(\"&  \" + line.replace(\"NA\", \"\")) #needs to be formated with an extra column\n",
    "                    \n",
    "                    if line.startswith(\"Task & Dataset\"): #start writing lines from covFile\n",
    "                        writeLine = True\n",
    "                            \n",
    "                        \n",
    "            covFile.close()\n",
    "                \n",
    "\n",
    "        collatedFile.write('\\end{tabular}\\n')\n",
    "        collatedFile.write('\\endgroup\\n')\n",
    "        collatedFile.write('\\end{table}\\n')\n",
    "        \n",
    "    collatedFile.close()\n",
    "        \n",
    "#run compile function\n",
    "compileSimple(RTSimple, covariates, 0)\n",
    "compileSimple(AccSimple, covariates, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403d241c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run compile function to generate two covariates per page\n",
    "i = 0\n",
    "pgcount = 1\n",
    "while i < len(covariates):\n",
    "    compileSimple(RTSimple, covariates[i:i+2], pgcount)\n",
    "    compileSimple(AccSimple, covariates[i:i+2], pgcount)\n",
    "    i += 2\n",
    "    pgcount +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd085297",
   "metadata": {},
   "source": [
    "### Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef97295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace results for AP datasets with models exclude nAdv from regression\n",
    "#replace any occurrence of 999 or 999.00 with \"\"; replace any occurence of NA with \"\"\n",
    "#adds additional formatting: greys out rows with insignificant effects; \"header\" for each task; remove task column\n",
    "#current output needs to be split into multiple pages manually as needed, or converted into longtable\n",
    "\n",
    "AccMulti = [f for f in texFiles if \"Acc_\" in f and \"+\" in f and not \"RC\" in f] #accuracy files\n",
    "RTMulti = [f for f in texFiles if \"RT_\" in f and \"+\" in f and not \"RC\" in f] #reaction time files\n",
    "\n",
    "\n",
    "def formatMulti(fileList):\n",
    "    #get beginning of file names\n",
    "    filePrefix = fileList[0].split('_')[0] \n",
    "    \n",
    "    shortFile = [f for f in fileList if not \"nAdv\" in f][0] #get AP datasets from this file\n",
    "    fullFile = [f for f in fileList if \"nAdv\" in f][0] #get megastudies datasets from this file\n",
    "    \n",
    "    with open('../FormattedLatexTables/'+filePrefix+'_multiple.tex',\"w\") as collatedFile:\n",
    "        collatedFile.write('\\\\begin{table}[H]\\n')\n",
    "        collatedFile.write('\\\\begingroup\\\\normalsize\\n')\n",
    "        collatedFile.write('\\\\begin{tabular}{=p{0cm}llr+l+r+r+r+r+r+l}\\n')\n",
    "        collatedFile.write('\\hline\\n')\n",
    "        collatedFile.write(' & Dataset & df & adj.r.sq & Predictor & b & SE & VIF & t & p &  \\\\\\\\ \\n')\n",
    "                 \n",
    "        with open(shortFile) as APFile:\n",
    "            writeLine = False\n",
    "                \n",
    "            for line in APFile:\n",
    "\n",
    "                splitLine = line.split(\"&\")\n",
    "\n",
    "                if len(splitLine) > 1:\n",
    "\n",
    "                    if \"AP\\_full\\_e\" in splitLine[1]: #start writing lines from APFile\n",
    "                        writeLine = True\n",
    "                    \n",
    "                    if \"BLP\" in splitLine[1]: #stop writing lines from APFile\n",
    "                        writeLine = False\n",
    "                        break\n",
    "                \n",
    "                if writeLine == True: \n",
    "                    if splitLine[0].strip().isalpha(): #i.e. there is a task heading\n",
    "                        collatedFile.write('\\multicolumn{10}{l}{\\\\textit{Task: ' + splitLine[0] +'}}\\\\\\\\\\n')\n",
    "                    if \"&   \\\\\" in line[-10:-1]:\n",
    "                        collatedFile.write('\\\\rowstyle{\\leavevmode\\color{gray}}\\n') #makes lines with no significance grey\n",
    "                    collatedFile.write(\"& \" + line[line.find('&')+1:].replace(\"NA\", \"\").replace(\"999.00\", \"\").replace(\"999\", \"\")) #write line from second column onwards\n",
    "                    \n",
    "                #elif writeLine == False:\n",
    "                #    break\n",
    "             \n",
    "        APFile.close()\n",
    "\n",
    "            \n",
    "        with open(fullFile) as megaFile:\n",
    "            writeLine = False\n",
    "                \n",
    "            for line in megaFile:\n",
    "                \n",
    "                splitLine = line.split(\"&\")\n",
    "                    \n",
    "                if len(splitLine) > 1:                \n",
    "                    if \"BLP\" in splitLine[1]: #start writing lines from megaFile\n",
    "                        writeLine = True\n",
    "                    if \"hline\" in line: #stop writing lines from megaFile\n",
    "                        writeLine = False\n",
    "                        break\n",
    "                \n",
    "                if writeLine == True: \n",
    "                    if splitLine[0].strip().isalpha(): #i.e. there is a task heading\n",
    "                        collatedFile.write('\\multicolumn{10}{l}{\\\\textit{Task: ' + splitLine[0] +'}}\\\\\\\\\\n')\n",
    "                    if \"&   \\\\\" in line[-10:-1]:\n",
    "                        collatedFile.write('\\\\rowstyle{\\leavevmode\\color{gray}}\\n') #makes lines with no significance grey\n",
    "                        \n",
    "                    collatedFile.write(\"& \" + line[line.find('&')+1:].replace(\"NA\", \"\").replace(\"999.00\", \"\").replace(\"999\", \"\")) #write line from second column onwards\n",
    "                    \n",
    "                        \n",
    "        megaFile.close()\n",
    "                \n",
    "\n",
    "        collatedFile.write('\\\\hline\\n')\n",
    "        collatedFile.write('\\end{tabular}\\n')\n",
    "        collatedFile.write('\\endgroup\\n')\n",
    "        collatedFile.write('\\end{table}\\n')\n",
    "        \n",
    "    collatedFile.close()\n",
    "        \n",
    "#run compile function\n",
    "formatMulti(RTMulti)\n",
    "formatMulti(AccMulti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9871fc1",
   "metadata": {},
   "source": [
    "### PCA Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93dd2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reads loadings from PCAloadings_dfMain2.txt and prints to .tex\n",
    "#assumes four components in the order of Lexical, Semantic, Sublexical and Part-of-Speech\n",
    "\n",
    "#covariates = [\"nNoun\", \"nVerb\", \"nAdj\", \"nAdv\", \"logWF\", \"nLet\", \"nSyll\", \"pld20\", \"old20\", \"posUni\",\\\n",
    "#              \"posBi\", \"SemD\", \"Conc\", \"SubCD\", \"MemCD\"]\n",
    "import re\n",
    "\n",
    "covLongest = max([len(cov) for cov in covariates])\n",
    "\n",
    "with open('../FormattedLatexTables/PCAloadings_rotated_dfMain2.tex',\"w\") as loadingsFile:\n",
    "    loadingsFile.write('\\\\begin{table}[H]\\n')\n",
    "    loadingsFile.write('\\\\centering\\n')\n",
    "    loadingsFile.write('\\\\caption{Loadings of principal component analysis on covariates with cutoff at .3} \\\\label{tab:dfMain2loadings}\\n')\n",
    "    loadingsFile.write('\\\\begingroup\\\\normalsize\\n')\n",
    "    loadingsFile.write('\\\\begin{tabular}{lrrrr}\\n')\n",
    "    loadingsFile.write('\\hline\\n')\n",
    "    loadingsFile.write('  & Component1 & Component2 & Component3 & Component 4\\\\\\\\\\n')\n",
    "    loadingsFile.write('  & (Lexical) & (Semantic) & (Sublexical) & (Part-of-Speech)\\\\\\\\\\n')\n",
    "    \n",
    "    with open('../PCA/PCAloadings_rotated_dfMain2.txt') as pcaFile:\n",
    "        writeLine = False\n",
    "            \n",
    "        for line in pcaFile:\n",
    "                \n",
    "            if \"loadings with cutoff at 0.3:\" in line: #take loadings from under this heading\n",
    "                writeLine = True\n",
    "                \n",
    "            if writeLine == True:\n",
    "                if \"RC\" in line:\n",
    "                    col_start = [m.start()-1 for m in re.finditer('RC', line)] #find character in line where column starts\n",
    "                if line[0:covLongest].strip() in covariates:\n",
    "                    delim_line = list(line) #find index to add \"&\" to deliminate columns\n",
    "                    for ind in col_start:\n",
    "                        delim_line[ind] = \"&\"\n",
    "                    loadingsFile.write(''.join(delim_line) + '\\\\\\\\\\n')\n",
    "                        \n",
    "        pcaFile.close()\n",
    "                \n",
    "    loadingsFile.write('\\hline\\n')\n",
    "    loadingsFile.write('\\end{tabular}\\n')\n",
    "    loadingsFile.write('\\endgroup\\n')\n",
    "    loadingsFile.write('\\end{table}\\n')\n",
    "        \n",
    "loadingsFile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2126be",
   "metadata": {},
   "source": [
    "## PCA Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c20402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace any occurence of NA with \"\"\n",
    "#adds additional formatting: greys out rows with insignificant effects; \"header\" for each task; remove task column\n",
    "#current output needs to be split into multiple pages manually as needed, or converted into longtable\n",
    "\n",
    "AccPCA = [f for f in texFiles if \"Acc_\" in f and \"+\" in f and \"RC\" in f] #accuracy files\n",
    "RTPCA = [f for f in texFiles if \"RT_\" in f and \"+\" in f and \"RC\" in f] #reaction time files\n",
    "\n",
    "\n",
    "def formatPCA(fileList):\n",
    "    filePrefix = fileList[0].split('_')[0]\n",
    "    with open('../FormattedLatexTables/'+filePrefix+'_PCAmulti.tex',\"w\") as pcaformattedFile:\n",
    "        pcaformattedFile.write('\\\\begin{table}[H]\\n')\n",
    "        pcaformattedFile.write('\\\\begingroup\\\\normalsize\\n')\n",
    "        pcaformattedFile.write('\\\\begin{tabular}{=p{0cm}llr+l+r+r+r+r+r+l}\\n')\n",
    "        pcaformattedFile.write('\\hline\\n')\n",
    "        pcaformattedFile.write(' & Dataset & df & adj.r.sq & Predictor & b & SE & VIF & t & p &  \\\\\\\\ \\n')\n",
    "        pcaformattedFile.write('\\hline\\n')\n",
    "                 \n",
    "        with open(AccPCA[0]) as pcaFile:\n",
    "            writeLine = False\n",
    "                \n",
    "            for line in pcaFile:\n",
    "                if \"\\hline\" in line:\n",
    "                    pcaformattedFile.write('\\hline\\n')\n",
    "                    writeLine = False\n",
    "\n",
    "                splitLine = line.split(\"&\")\n",
    "\n",
    "                if len(splitLine) > 1:\n",
    "\n",
    "                    if \"AP\\_full\\_e\" in splitLine[1]: #start writing lines from APFile\n",
    "                        writeLine = True\n",
    "                    \n",
    "                \n",
    "                if writeLine == True: \n",
    "\n",
    "                    if splitLine[0].strip().isalpha(): #i.e. there is a task heading\n",
    "                        pcaformattedFile.write('\\multicolumn{10}{l}{\\\\textit{Task: ' + splitLine[0] +'}}\\\\\\\\\\n')\n",
    "                    if \"&   \\\\\" in line[-10:-1]:\n",
    "                        pcaformattedFile.write('\\\\rowstyle{\\leavevmode\\color{gray}}\\n') #makes lines with no significance grey\n",
    "                    pcaformattedFile.write(\"& \" + line[line.find('&')+1:].replace(\"NA\", \"\").replace(\"999.00\", \"\").replace(\"999\", \"\")) #write line from second column onwards\n",
    "\n",
    "        pcaFile.close()\n",
    "\n",
    "\n",
    "        pcaformattedFile.write('\\end{tabular}\\n')\n",
    "        pcaformattedFile.write('\\endgroup\\n')\n",
    "        pcaformattedFile.write('\\end{table}\\n')\n",
    "        \n",
    "    pcaformattedFile.close()\n",
    "        \n",
    "#run compile function\n",
    "formatPCA(RTPCA)\n",
    "formatPCA(AccPCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f6248",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef37187",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grab regression b and p values from collated excel table dfMain2_allCovariates.csv and write to reference sheet on summaryTable.xlsx\n",
    "#mapping of PCA to covariate loadings manually set according to PCA loadings output (winner takes all)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "allModels = pd.read_csv('../ExcelTables/dfMain2_allCovariates.csv', header = None)\n",
    "\n",
    "RC_cov_map = pd.DataFrame(columns=[\"component\", \"covariate\"])\n",
    "RC_cov_map.covariate = covariates\n",
    "RC_cov_map.component = [\"RC4\", \"RC2\", \"RC4\", \"RC4\", \"RC4\", \"RC2\", \"RC2\", \"RC2\", \"RC2\", \n",
    "                        \"RC1\", \"RC1\", \"RC1\", \"RC1\", \"RC3\", \"RC3\"]\n",
    "\n",
    "models = ['AP_full_e', 'AP_deg_h', 'BLP', 'ELP_LD', 'AELP', 'MALD', 'ELP_NMG', 'SDP']\n",
    "\n",
    "interactions  = [\"NOS:\" + cov for cov in covariates]+[\"NOS:RC1\", \"NOS:RC2\", \"NOS:RC3\", \"NOS:RC4\"]\n",
    "\n",
    "summary_cols = ['AP_full_e_simple', 'AP_full_e_multi', 'AP_full_e_pca',\n",
    "                'AP_deg_h_simple', 'AP_deg_h_multi', 'AP_deg_h_pca',\n",
    "                'BLP_simple', 'BLP_multi', 'BLP_pca',\n",
    "                'ELP_LD_simple', 'ELP_LD_multi', 'ELP_LD_pca',\n",
    "                'AELP_simple', 'AELP_multi', 'AELP_pca',\n",
    "                'MALD_simple', 'MALD_multi', 'MALD_pca',\n",
    "                'ELP_NMG_simple', 'ELP_NMG_multi', 'ELP_NMG_pca',\n",
    "                'SDP_simple', 'SDP_multi', 'SDP_pca']\n",
    "\n",
    "\n",
    "RTb = pd.DataFrame(columns=summary_cols, index=pd.Index(covariates))\n",
    "Accb = pd.DataFrame(columns=summary_cols, index=pd.Index(covariates))\n",
    "\n",
    "RTp = pd.DataFrame(columns=summary_cols, index=pd.Index(covariates))\n",
    "Accp = pd.DataFrame(columns=summary_cols, index=pd.Index(covariates))\n",
    "\n",
    "\n",
    "AccModels = allModels.iloc[:, 0:10]\n",
    "RTModels = allModels.iloc[:, np.r_[0:3, 11:18]]\n",
    "\n",
    "AccModels.columns = AccModels.iloc[2]\n",
    "RTModels.columns = RTModels.iloc[2]\n",
    "\n",
    "AccModels['Dataset'].fillna(method='ffill', inplace = True)\n",
    "RTModels['Dataset'].fillna(method='ffill', inplace = True)\n",
    "\n",
    "AccModels['Task'].fillna(\"\", inplace = True)\n",
    "RTModels['Task'].fillna(\"\", inplace = True)\n",
    "\n",
    "\n",
    "modelstarts = RTModels.loc[RTModels['Task'].str.contains(\"~ NOS\"), 'Task']\n",
    "modelstarts_df = pd.DataFrame({'rownum':modelstarts.index, 'formula':modelstarts, 'rtype':\"\"})\n",
    "modelstarts_df.loc[modelstarts_df['formula'].str.contains(\"RC\"), 'rtype'] = \"pca\"\n",
    "modelstarts_df.loc[modelstarts_df['formula'].str.contains(\"nAdv\"), 'rtype'] = \"multi\"\n",
    "modelstarts_df.loc[~(modelstarts_df['formula'].str.contains(\"\\+\")), 'rtype'] = \"simple\"\n",
    "modelstarts_df.loc[modelstarts_df['rtype'] == \"\", 'rtype'] = \"multi_AP\"\n",
    "modelstarts_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "#slice out every model by modelstarts_df.rownum, get rows containing interaction, \n",
    "#fill in b and p by corresponding dataset, covariate, and rtype\n",
    "\n",
    "for i in range(len(modelstarts_df)):\n",
    "    startidx = modelstarts_df.iloc[i].rownum + 3\n",
    "    if i < len(modelstarts_df)-1:\n",
    "        stopidx = modelstarts_df.iloc[i+1].rownum\n",
    "    else: \n",
    "        stopidx = len(AccModels)\n",
    "            \n",
    "    modelslice_Acc = AccModels[startidx:stopidx]\n",
    "    modelint_Acc = modelslice_Acc.loc[modelslice_Acc['Predictor'].isin(interactions)]\n",
    "    \n",
    "    modelslice_RT = RTModels[startidx:stopidx]\n",
    "    modelint_RT = modelslice_RT.loc[modelslice_RT['Predictor'].isin(interactions)]\n",
    "\n",
    "    #print(modelstarts_df.iloc[i].rtype)\n",
    "    if modelstarts_df.iloc[i].rtype == 'multi_AP':\n",
    "        modelint_Acc = modelint_Acc.loc[modelint_Acc['Dataset'].str.contains(\"AP\")]\n",
    "        modelint_RT = modelint_RT.loc[modelint_RT['Dataset'].str.contains(\"AP\")]\n",
    "    if modelstarts_df.iloc[i].rtype == 'multi':\n",
    "        modelint_Acc = modelint_Acc.loc[~modelint_Acc['Dataset'].str.contains(\"AP\")]\n",
    "        modelint_RT = modelint_RT.loc[~modelint_RT['Dataset'].str.contains(\"AP\")]\n",
    "        \n",
    "    for index, row in modelint_Acc.iterrows():\n",
    "        targetcol = row['Dataset'] + \"_\" + modelstarts_df.iloc[i].rtype.replace(\"_AP\", \"\")\n",
    "        targetrow = row['Predictor'].replace(\"NOS:\",\"\")\n",
    "        if modelstarts_df.iloc[i].rtype == 'pca':\n",
    "            targetrow = RC_cov_map.loc[RC_cov_map.component == targetrow, \"covariate\"]\n",
    "            Accb.loc[Accb.index.isin(targetrow), targetcol] = row['b']\n",
    "            Accp.loc[Accp.index.isin(targetrow), targetcol] = row['p']\n",
    "        else:\n",
    "            Accb.loc[targetrow, targetcol] = row['b']\n",
    "            Accp.loc[targetrow, targetcol] = row['p']\n",
    "    \n",
    "\n",
    "    for index, row in modelint_RT.iterrows():\n",
    "        targetcol = row['Dataset'] + \"_\" + modelstarts_df.iloc[i].rtype.replace(\"_AP\", \"\")\n",
    "        targetrow = row['Predictor'].replace(\"NOS:\",\"\")\n",
    "        if modelstarts_df.iloc[i].rtype == 'pca':\n",
    "            targetrow = RC_cov_map.loc[RC_cov_map.component == targetrow, \"covariate\"]\n",
    "            RTb.loc[RTb.index.isin(targetrow), targetcol] = row['b']\n",
    "            RTp.loc[RTp.index.isin(targetrow), targetcol] = row['p']\n",
    "        else:\n",
    "            RTb.loc[targetrow, targetcol] = row['b']\n",
    "            RTp.loc[targetrow, targetcol] = row['p']\n",
    "\n",
    "#write to excel            \n",
    "            \n",
    "newrow_pHeader = pd.DataFrame([[None for _ in range(len(summary_cols)+1)],])\n",
    "newrow_pHeader[0] = \"Interaction p-value\"\n",
    "newrow_bHeader = pd.DataFrame([[None for _ in range(len(summary_cols)+1)],])\n",
    "newrow_bHeader[0] = \"Interaction slope\"\n",
    "\n",
    "writer = pd.ExcelWriter(\"../ExcelTables/summaryTable_values.xlsx\", mode = 'w', engine='openpyxl')\n",
    "newrow_pHeader.to_excel(writer,sheet_name = \"Accuracy\", index=False, header=False)\n",
    "Accp.to_excel(writer,sheet_name = \"Accuracy\", startrow = 2)\n",
    "newrow_bHeader.to_excel(writer,sheet_name = \"Accuracy\", index=False, header=False, startrow = 20)\n",
    "Accb.to_excel(writer,sheet_name = \"Accuracy\", startrow = 22)\n",
    "writer.save()\n",
    "writer.close()\n",
    "\n",
    "writer = pd.ExcelWriter(\"../ExcelTables/summaryTable_values.xlsx\", mode = 'a', engine='openpyxl')\n",
    "newrow_pHeader.to_excel(writer,sheet_name = \"ReactionTime\", index=False, header=False)\n",
    "RTp.to_excel(writer,sheet_name = \"ReactionTime\", startrow = 2)\n",
    "newrow_bHeader.to_excel(writer,sheet_name = \"ReactionTime\", index=False, header=False, startrow = 20)\n",
    "RTb.to_excel(writer,sheet_name = \"ReactionTime\", startrow = 22)\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae382c",
   "metadata": {},
   "source": [
    "## Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51d143ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts text descriptives of original dataset to sideways table -- swap out header and footer\n",
    "\n",
    "with open('../FormattedLatexTables/Descriptives_original.tex',\"w\") as formatteddescFile:\n",
    "    formatteddescFile.write('\\\\begin{sidewaystable}[ph!]\\n')\n",
    "    formatteddescFile.write('\\\\begin{tabular}{p{2.9cm}p{1.8cm}p{3.8cm}p{5.8cm}p{1.15cm}p{1.7cm}p{1.15cm}p{1.6cm}}\\n')\n",
    "    formatteddescFile.write('\\\\hline\\n')\n",
    "    \n",
    "    with open('../Descriptives/Descriptives_original.tex') as descFile:\n",
    "        writeLine = False\n",
    "            \n",
    "        for line in descFile:\n",
    "                \n",
    "            if \"Dataset\" in line: #take loadings from under this heading\n",
    "                writeLine = True\n",
    "                \n",
    "            if writeLine == True:\n",
    "                    formatteddescFile.write(line)\n",
    "                    \n",
    "                    if 'hline' in line:\n",
    "                        writeLine == False\n",
    "                        \n",
    "                        \n",
    "        descFile.close()\n",
    "                \n",
    "    formatteddescFile.write('\\n\\end{tabular}\\n')\n",
    "    \n",
    "\n",
    "    formatteddescFile.write('\\\\caption{Descriptive statistics of original datasets} \\\\label{tab:DescriptivesOriginal}\\n')\n",
    "    formatteddescFile.write('\\end{sidewaystable}\\n')\n",
    "        \n",
    "formatteddescFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05b5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add hline between datasets, remove repeated information\n",
    "\n",
    "with open('../FormattedLatexTables/Descriptives_current.tex',\"w\") as formatteddescFile:\n",
    "    formatteddescFile.write('\\\\begin{table}[H]\\n')\n",
    "    formatteddescFile.write('\\\\begingroup\\\\normalsize\\n')\n",
    "    formatteddescFile.write('\\\\hspace*{-1.5cm}\\n')\n",
    "    formatteddescFile.write('\\\\begin{tabular}{lllllll}\\n')\n",
    "    with open('../Descriptives/Descriptives_currentdfMain2.tex') as descFile:\n",
    "        writeLine = False\n",
    "   \n",
    "        for line in descFile:\n",
    "                \n",
    "            if \"Dataset\" in line: #take loadings from under this heading\n",
    "                writeLine = True\n",
    "                \n",
    "            if writeLine == True:\n",
    "                    \n",
    "                if '&' in line:\n",
    "\n",
    "                    if not line[0: line.index('&')].strip() == lastLine[0: line.index('&')].strip(): #i.e. first occurrence\n",
    "                        formatteddescFile.write('\\hline\\n')\n",
    "                        formatteddescFile.write(line)\n",
    "                        \n",
    "                    else: \n",
    "                        lineSplit = line.split(\"&\")\n",
    "                        lineSplit[0:2] = \" \"\n",
    "                        formatteddescFile.write(\"&\" + (\"&\".join(lineSplit)))\n",
    "                    \n",
    "                    if '\\hline' in line:\n",
    "                        writeLine == False\n",
    "                        \n",
    "            lastLine = line\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        \n",
    "        descFile.close()\n",
    "                \n",
    "    formatteddescFile.write('\\hline\\n')\n",
    "    formatteddescFile.write('\\end{tabular}\\n')\n",
    "    formatteddescFile.write('\\endgroup\\n')\n",
    "    formatteddescFile.write('\\end{table}\\n')\n",
    "\n",
    "formatteddescFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104f56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
